{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using deep learning model to generate Harry Potter-liked stories . Given a sequence of words as seed, this model predicts the following words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import required python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import initializers\n",
    "import string\n",
    "import time\n",
    "from random import randint\n",
    "import numpy as np\n",
    "from pickle import dump, load\n",
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HarryPotter-en/Harry-Potter-and-the-Chamber-of-Secrets.txt',\n",
       " 'HarryPotter-en/Harry-Potter-and-the-Deathly-Hallows.txt',\n",
       " 'HarryPotter-en/Harry-Potter-and-the-Goblet-of-Fire.txt',\n",
       " 'HarryPotter-en/Harry-Potter-and-the-Half-Blood-Prince.txt',\n",
       " 'HarryPotter-en/Harry-Potter-and-the-Order-of-the-Phoenix.txt',\n",
       " 'HarryPotter-en/Harry-Potter-and-the-Philosophers-Stone.txt',\n",
       " 'HarryPotter-en/Harry-Potter-and-the-Prisoner-of-Azkaban.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare dataset\n",
    "directory = 'HarryPotter-en/'\n",
    "fnames = os.listdir(directory)\n",
    "fnames.sort()\n",
    "\n",
    "txt_data_files = []\n",
    "for f in fnames:\n",
    "    txt_data_files.append(os.path.join(directory, f))\n",
    "txt_data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load text data\n",
    "def load_txt_data(filename):\n",
    "    file = open(filename, 'r')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter was a highly unusual boy in many ways. For one thing, he hated the summer holidays more than any other time of year. For another, he really wanted to do his homework but was forced to do \n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "txt_data_set = ''\n",
    "for f in txt_data_files:\n",
    "    txt_data_set += load_txt_data(f)\n",
    "    txt_data_set = load_txt_data(f)\n",
    "print(txt_data_set[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-process the text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. replace '--' with a space ' '.\n",
    "2. tokenize the text by whits space\n",
    "3. remove puntuation from each token\n",
    "4. remove all tokens that are not alphabetic\n",
    "5. convert to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_txt_dataset(txt_data):\n",
    "    txt_data = txt_data.replace('--', ' ')  # replace '--' with a space ' '\n",
    "    txt_data = txt_data.lower().strip()\n",
    "    # creating a space between a word and the punctuation following it    \n",
    "    #txt_data = re.sub(r\"([?.!,¿])\", r\" \\1 \", txt_data)\n",
    "    #txt_data = re.sub(r'[\" \"]+', \" \", txt_data)\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    #txt_data = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", txt_data)\n",
    "    txt_data = txt_data.rstrip().strip()\n",
    "    \n",
    "    tokens = txt_data.split()  # split into tokens by white space\n",
    "    table = str.maketrans('', '', string.punctuation)  # remove punctuation from each token\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    tokens = [word for word in tokens if word.isalpha()]  # remove remaining tokens that are not alphabetic\n",
    "    #tokens = [word.lower() for word in tokens]  # make lower case\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['not', 'for', 'the', 'first', 'time', 'an', 'argument', 'had', 'broken', 'out', 'over', 'breakfast', 'at', 'number', 'four', 'privet', 'drive', 'mr', 'vernon', 'dursley', 'had', 'been', 'woken', 'in', 'the', 'early', 'hours', 'of', 'the', 'morning', 'by', 'a', 'loud', 'hooting', 'noise', 'from', 'his', 'nephew', 'room', 'time', 'this', 'he', 'roared', 'across', 'the', 'table', 'you', 'control', 'that', 'owl', 'have', 'to', 'harry', 'tried', 'yet', 'again', 'to', 'explain', 'he', 'said', 'used', 'to', 'flying', 'around', 'outside', 'if', 'i', 'could', 'just', 'let', 'her', 'out', 'at', 'i', 'look', 'snarled', 'uncle', 'vernon', 'a', 'bit', 'of', 'fried', 'egg', 'dangling', 'from', 'his', 'bushy', 'mustache', 'know', 'happen', 'if', 'that', 'let', 'he', 'exchanged', 'dark', 'looks', 'with', 'his', 'wife', 'petunia', 'harry', 'tried', 'to', 'argue', 'back', 'but', 'his', 'words', 'were', 'drowned', 'by', 'a', 'long', 'loud', 'belch', 'from', 'the', 'son', 'dudley', 'want', 'more', 'more', 'in', 'the', 'frying', 'pan', 'said', 'aunt', 'petunia', 'turning', 'misty', 'eyes', 'on', 'her', 'massive', 'son', 'must', 'build', 'you', 'up', 'while', 'got', 'the', 'i', 'like', 'the', 'sound', 'of', 'that', 'school', 'petunia', 'i', 'never', 'went', 'hungry', 'when', 'i', 'was', 'at', 'said', 'uncle', 'vernon', 'heartily', 'gets', 'enough', 'you', 'dudley', 'who', 'was', 'so', 'large', 'his', 'bottom', 'drooped', 'over', 'either', 'side', 'of', 'the', 'kitchen', 'chair', 'grinned', 'and', 'turned', 'to', 'harry', 'the', 'frying', 'forgotten', 'the', 'magic', 'said', 'harry', 'irritably', 'the', 'effect', 'of', 'this', 'simple']\n",
      "Total Tokens: 448827\n",
      "Unique Tokens: 16107\n"
     ]
    }
   ],
   "source": [
    "# Pre-process and tokenize document\n",
    "tokens = preprocess_txt_dataset(txt_data_set)\n",
    "print(tokens[:200])\n",
    "print('Total Tokens: %d' % len(tokens))\n",
    "print('Unique Tokens: %d' % len(set(tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organize the text data into sequences of tokens. Each sequence has a length of 50+1 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 448776\n"
     ]
    }
   ],
   "source": [
    "# organize into sequences of tokens\n",
    "length = 50 + 1\n",
    "#length = 7 + 1\n",
    "txt_sequences = list()\n",
    "\n",
    "for i in range(length, len(tokens)):\n",
    "    # select sequence of tokens\n",
    "    seq = tokens[i-length:i]\n",
    "    # convert into a line\n",
    "    line = ' '.join(seq)\n",
    "    # store\n",
    "    txt_sequences.append(line)\n",
    "print('Total Sequences: %d' % len(txt_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_txt_data(txt_lines, filename):\n",
    "    text = '\\n'.join(txt_lines)\n",
    "    file = open(filename, 'w')\n",
    "    file.write(text)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save sequences to file\n",
    "out_filename = 'HarryPotter_series.txt'\n",
    "save_txt_data(txt_sequences, out_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the text sequences by Tokenizer of keras. The output is sequences of word index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(txt_sequences)\n",
    "sequences = tokenizer.texts_to_sequences(txt_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are total 7731 vocablaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16108\n"
     ]
    }
   ],
   "source": [
    "# vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare word sequences for gensim word2vec model training. The word_sequences is a 2D array of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_sequences = []\n",
    "\n",
    "for i in range(len(txt_sequences)):\n",
    "    word_sequences.append(txt_sequences[i].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['not', 'for', 'the', 'first', 'time', 'an', 'argument', 'had', 'broken', 'out', 'over', 'breakfast', 'at', 'number', 'four', 'privet', 'drive', 'mr', 'vernon', 'dursley', 'had', 'been', 'woken', 'in', 'the', 'early', 'hours', 'of', 'the', 'morning', 'by', 'a', 'loud', 'hooting', 'noise', 'from', 'his', 'nephew', 'room', 'time', 'this', 'he', 'roared', 'across', 'the', 'table', 'you', 'control', 'that', 'owl', 'have'], ['for', 'the', 'first', 'time', 'an', 'argument', 'had', 'broken', 'out', 'over', 'breakfast', 'at', 'number', 'four', 'privet', 'drive', 'mr', 'vernon', 'dursley', 'had', 'been', 'woken', 'in', 'the', 'early', 'hours', 'of', 'the', 'morning', 'by', 'a', 'loud', 'hooting', 'noise', 'from', 'his', 'nephew', 'room', 'time', 'this', 'he', 'roared', 'across', 'the', 'table', 'you', 'control', 'that', 'owl', 'have', 'to']]\n"
     ]
    }
   ],
   "source": [
    "print(word_sequences[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 256  # embedding dimension of word2vec model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gensim model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_model = Word2Vec(word_sequences, size = embedding_dim, iter=5, sg=1, window=5, min_count=5, max_vocab_size=None, hs=0, negative=5, workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_model.save('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_model = Word2Vec.load('word2vec.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the word vectors trained by gensim and prepare an embedding matrix for the initialization of Embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "for w in gensim_model.wv.vocab:\n",
    "    word_vectors = np.array([gensim_model[w]])\n",
    "    embedding_matrix[tokenizer.word_index[w]] = word_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the performance of the model trained by gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('on', 0.3945864737033844),\n",
       " ('that', 0.38677656650543213),\n",
       " ('the', 0.3813679814338684),\n",
       " ('all', 0.37862300872802734),\n",
       " ('it', 0.37540748715400696),\n",
       " ('had', 0.3650192618370056),\n",
       " ('and', 0.35878318548202515),\n",
       " ('at', 0.35357147455215454),\n",
       " ('for', 0.34648340940475464),\n",
       " ('who', 0.3339601755142212)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_model.most_similar('one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12400773"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_model.similarity('harry', 'wizard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the training dataset and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate into training data and label\n",
    "sequences = np.array(sequences)\n",
    "X, y = sequences[:,:-1], sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab_size)  # One-hot encoding\n",
    "seq_length = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_cell = 256\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Define a deep learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a deep learning sequential model with one embedding layer initialized by the word vectors pre-trained by gensim, two LSTM layers with 256 memory cells, one dropout layer with dropout rate 0.2, one dense layer with 256 neurons and relu activation, another dropout layer with dropout rate 0.2, and one output dense layer with 7731 neurons and softmax activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 50, 256)           4123648   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 50, 256)           525312    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16108)             4139756   \n",
      "=================================================================\n",
      "Total params: 9,379,820\n",
      "Trainable params: 5,256,172\n",
      "Non-trainable params: 4,123,648\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "harry_potter_model = Sequential()\n",
    "harry_potter_model.add(Embedding(vocab_size, embedding_dim, input_length=seq_length, \n",
    "    embeddings_initializer=initializers.Constant(embedding_matrix), trainable=False,))\n",
    "harry_potter_model.add(LSTM(memory_cell, return_sequences=True))\n",
    "harry_potter_model.add(LSTM(memory_cell))\n",
    "harry_potter_model.add(Dropout(dropout_rate))\n",
    "harry_potter_model.add(Dense(memory_cell, activation='relu'))\n",
    "harry_potter_model.add(Dropout(dropout_rate))\n",
    "harry_potter_model.add(Dense(vocab_size, activation='softmax'))\n",
    "harry_potter_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "harry_potter_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Harry-Potter style text generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始時間是： Fri Oct 16 14:07:17 2020\n",
      "結束時間是： Fri Oct 16 14:07:17 2020\n",
      "Elapsed time:  0.0021424293518066406\n",
      "00:00:00\n"
     ]
    }
   ],
   "source": [
    "tick1 = time.time()\n",
    "localtime = time.asctime(time.localtime(time.time()))\n",
    "print(\"開始時間是：\", localtime)\n",
    "\n",
    "# fit model\n",
    "harry_potter_model.fit(X, y, validation_split=0.2, batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "localtime = time.asctime(time.localtime(time.time()))\n",
    "print(\"結束時間是：\", localtime)\n",
    "\n",
    "tick2 = time.time()\n",
    "print(\"Elapsed time: \", tick2 - tick1)\n",
    "print(time.strftime(\"%H:%M:%S\", time.localtime(tick2-tick1-3600*8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to file\n",
    "harry_potter_model.save('harry_potter_model.h5')\n",
    "# save the tokenizer\n",
    "dump(tokenizer, open('harry_potter_tokenizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "seq_length = len(txt_sequences[0].split()) - 1\n",
    "print(seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "harry_potter_model = load_model('harry_potter_model.h5')\n",
    "# load the tokenizer\n",
    "tokenizer = load(open('harry_potter_tokenizer.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic sampling introduces randomness in the sampling process, by sampling from\n",
    "the probability distribution for the next word. In order to control the amount of stochasticity in the sampling process, a parameter called the softmax temperature that characterizes the entropy of the probability distribution is introduced. Given a temperature value, a new probability distribution is computed from the predicted probability distribution of the model. Higher temperature results in higher entropy of the new probability distribution and generates more creative text data. On the contrary, lower temperature results in less randomness of the distribution and generates much more predictable data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_gen_sample(preds, temperature=0.5):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sequence from a language model\n",
    "def generate_txt_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
    "    result = list()\n",
    "    \n",
    "    # generate n_words of words\n",
    "    for _ in range(n_words):\n",
    "        # tokenize the seed text sequence\n",
    "        encoded = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "\n",
    "        # truncate sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, padding='pre', truncating='pre')\n",
    "        # predict probabilities of the next word\n",
    "        preds = model.predict(encoded, verbose=0)\n",
    "        # Stochastic sampling with temperature 0.5\n",
    "        idx = txt_gen_sample(preds[0], 0.5)\n",
    "        \n",
    "        # map the predicted index to word\n",
    "        out_word = tokenizer.index_word[idx]\n",
    "        \n",
    "        # append to the seed text\n",
    "        seed_text += ' ' + out_word\n",
    "        # append to the generated text sequence\n",
    "        result.append(out_word)\n",
    "\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the seed text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['generated_story/story1.txt',\n",
       " 'generated_story/story2.txt',\n",
       " 'generated_story/story3.txt']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = 'generated_story/'\n",
    "\n",
    "if os.path.isfile('generated_story/gen_story1.txt'):\n",
    "    os.remove('generated_story/gen_story1.txt')\n",
    "if os.path.isfile('generated_story/gen_story2.txt'):\n",
    "    os.remove('generated_story/gen_story2.txt')\n",
    "if os.path.isfile('generated_story/gen_story3.txt'):\n",
    "    os.remove('generated_story/gen_story3.txt')\n",
    "    \n",
    "fnames = os.listdir(directory)\n",
    "fnames.sort()\n",
    "seed_txt_files = []\n",
    "for f in fnames:\n",
    "    seed_txt_files.append(os.path.join(directory, f))\n",
    "seed_txt_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate 250 words for each seed text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story: 1\n",
      "Seed Text: mr dursley might have been drifting into an uneasy sleep\n",
      "\n",
      "Generated Story: mr dursley might have been drifting into an uneasy sleep\n",
      "he wished theyd acted remotely of guilt sticking up to the top of the common room the chamber of secrets has been given mum and dad said him as though this question was cracked and woken that was moving to the rest of the school apparently expected to encounter the diet of the boy who was crying asleep before the grave to the lightning scar on forehead but sense he sat at ron and harry together ron they hurried away from the wizards who looked at each other in celebration watching the gryffindors pavement more odd faces you cars in october five minutes or so the goblin minister exploded in her hand and continued to glare in turning think stupid lets try and give me a quick word i dozed yer staying to get past a dragon to stop the slytherins to the floo network wizarding creatures the class may be revealed to warn that a witch has been petrified is it sir patrick defensive the whole story said hagrid you can attend for those schools have seen the end of the daily prophet ive seen a nasty charm in a champion i know yes said mr weasley quietly as they approached the table his knuckles echoed his lips absentmindedly her lip think youve got a apparition excellent considerably known lead anyway ah plugs starting to seize out a stack of pumpkin juice and one of these words hasnt got anything to do spells they said fred choked his glasses\n",
      "\n",
      "Story: 2\n",
      "Seed Text: harry and hermione walked on the street\n",
      "\n",
      "Generated Story: harry and hermione walked on the street\n",
      "and down the hall for likely badly injured descending and helping solid wroughtiron harry let out a swift witch with emotion wearily and concentration wait for the snitch harry bent down and threw it over shoulder and dropping holding it at the teachers table harry watched her supposing a little start close to fetch the bulgarian weasley threw their lead to fall with difficulty ends and shining in their cloaks and started to rain mainly of the four beds and cleared with gold water as they approached the burrow she reached through a steep room ron groaned are fine yes said mr weasley her eyes flashing dazzlingly face and narrowly him harry saw a nervous nod and scrambled in the seat a few inches out stars filling a completed stopping twice we get them off near the kitchens arthur weasley said charlie hurry to the boil department and george and george laughed a younger man and ludo bagman who had left the table saying said ron checking a letter to get out of the said ron in disbelief told me you need said harry you reckon just move the governors may be said ron in mock outrage said mr crouch lovely said rita skeeter and shocked krum looked rather very weak not looking at xenophilius said dirk heavily suddenly smile pointing at him and the fat lady still did it then what are you showing the impression of the slytherins and the ministry will retreat to get near for lead\n",
      "\n",
      "Story: 3\n",
      "Seed Text: ron joined the gryffindor quidditch team and\n",
      "\n",
      "Generated Story: ron joined the gryffindor quidditch team and\n",
      "charlie showed him as they stepped into the he stepped forward and beating a fiery car and felt hot and slime yet carrying a number of reference journey in the deserted marble garden and the veela had appeared open the article began to climb stoatshead hill corridor opposite the walls shone high above it harry saw a pearly green witch madame delacour zoomed away backward and glittering up in the drawers they gathered the way to wake at the car knocking the class sprang toward the bike boys and rose on the wall waiting and onto a punctured party fred and george who had been sitting in midair dark brightly enough to steal close to harry and ron be in his bedroom harry wondered whether he was facing the others he walked around the room the gryffindor chasers was easily their heads of gryffindor tower where seemed a second crash swept past them and harry saw the bike scattered a few feet from the lower berth of the wellington trees and gleaming in the air harry ran upward to his feet and disappeared and pulled sight of the gnarled letter beside the other side of the field and the entrance to the high windows drew the beam of spiders moving along the corridors and were knocked backward as he felt the heat of the golden egg fell popping sparks the size of gold juice spread itself around the edge of the forbidden forest and lungs he zoomed out of the\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_words = 250\n",
    "\n",
    "for i, s in enumerate(seed_txt_files):\n",
    "    seed_text = load_txt_data(s)\n",
    "    #generate new text\n",
    "    generated_seq = generate_txt_seq(harry_potter_model, tokenizer, seq_length, seed_text, num_words)\n",
    "    \n",
    "    # Save to file\n",
    "    file = open(directory+'gen_'+fnames[i], 'w')\n",
    "    file.write(seed_text+generated_seq)\n",
    "    file.close()\n",
    "    print(f'Story: {i+1}')\n",
    "    print(f'Seed Text: {seed_text}')\n",
    "    print(f'Generated Story: {seed_text+generated_seq}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
